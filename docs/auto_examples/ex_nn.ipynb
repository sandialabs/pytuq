{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Residual Neural Network Construction\n\nThis example demonstrates how to use the Neural Network wrapper class, ``pytuq.surrogates.nn`` with scalar valued functions.\nThe constructor of the NN class accepts in an optional dictionary, ``net_options``, to specify additional hyperparameters. \nThe ``build()`` and ``evaluate()`` functions similarly accept dictionaries and explicit keyword arguments during their respective function calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\nimport torch\nimport numpy as np\n\nfrom pytuq.surrogates.nn import NN\nfrom quinn.solvers.nn_vi import NN_VI\nfrom quinn.nns.rnet import RNet, Poly\nfrom quinn.utils.plotting import myrc\nfrom quinn.utils.maps import scale01ToDom\nfrom quinn.func.funcs import Sine, Sine10, blundell\n\ndef main():\n    \"\"\"Main function.\"\"\"\n    torch.set_default_dtype(torch.double)\n    myrc()\n\n    #################################################################################\n    #################################################################################\n\n    # defaults to cuda:0 if available\n    device_id='cuda:0'\n    device = torch.device(device_id if torch.cuda.is_available() else 'cpu')\n    print(\"Using device\",device)\n\n    nall = 15 # total number of points\n    trn_factor = 0.9 # which fraction of nall goes to training\n    ntst = 13 # separate test set\n    ndim = 1 # input dimensionality\n    datanoise = 0.02 # Noise in the generated data\n    true_model, nout = Sine, 1  # Scalar valued output example\n\n    #################################################################################\n    #################################################################################\n\n    # Domain: defining range of input variable\n    domain = np.tile(np.array([-np.pi, np.pi]), (ndim, 1))\n\n    np.random.seed(111)\n\n    # Generating x-y training, validation, and testing data\n    xall = scale01ToDom(np.random.rand(nall, ndim), domain)\n    if true_model is not None:\n        yall = true_model(xall, datanoise=datanoise)\n\n    if ntst > 0:\n        np.random.seed(100)\n        xtst = scale01ToDom(np.random.rand(ntst, ndim), domain)\n        if true_model is not None:\n            ytst = true_model(xtst, datanoise=datanoise)\n\n    # (1) Initialize neural network with optional parameters for object instantiation\n    net_options = {'wp_function': Poly(0),\n                   'indim': ndim, \n                   'outdim': nout,\n                   'layer_pre': True,\n                   'layer_post': True,\n                   'biasorno': True,\n                   'nonlin': True,\n                   'mlp': False, \n                   'final_layer': None,\n                   'device': device,\n                   }\n\n    # Pass in unpacked net_options dict to constructor through kwargs\n    nnet = NN('RNet', 3, 3, **net_options)\n    \n    # (1.5) Split data into training and validation, assign through member functions\n    ntrn = int(trn_factor * nall)\n    indperm = range(nall) # np.random.permutation(range(nall))\n    indtrn = indperm[:ntrn]\n    indval = indperm[ntrn:]\n    xtrn, xval = xall[indtrn, :], xall[indval, :]\n    ytrn, yval = yall[indtrn, :], yall[indval, :]\n\n    nnet.set_validation_data(xval, yval) # optional\n    nnet.set_training_data(xtrn, ytrn)\n\n    # (2) 1st build: Call build function (defaults to UQ method of variational inference) with optional parameters for fitting\n    nnet.build(datanoise=datanoise, lrate=0.01, batch_size=None, nsam=1, nepochs=5000, verbose=False)\n\n    results = nnet.evaluate(xtst, nsam = 100, msc = 2) # Return samples of predictions with variance + covariance\n    print(\"Y_eval:\", results['Y_eval'], end=\"\\n\\n\") # Printing only samples of predictions\n\n    # (3) 2nd build: Example of throwing an exception when passing in a network option through build()\n    # fit_options = {'datanoise': 0.05,\n    #                'outdim': 3,\n    #                'lrate': 0.01,\n    #                'batch_size': None,\n    #                'nsam': 1,\n    #                'nepochs': 300,\n    #                'verbose': False\n    #                }\n\n    # nnet.build(**fit_options)\n    # results = nnet.evaluate(xtst, nsam = 100, msc = 2)\n    # print(results)\n\n\nif __name__ == '__main__':\n    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}